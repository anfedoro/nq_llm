{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2847338, 65])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#work with body vocab\n",
    "\n",
    "#load data from hdf5 file and create a dataset\n",
    "with h5py.File(\"data/nq17-23_1min_candle_seq_1024.hdf5\", \"r\") as f:\n",
    "    # total_records = f[\"data\"].shape[0]\n",
    "    # start_index = int(total_records*0.55)\n",
    "    # stop_index = int(total_records*0.65)\n",
    "    dataset = f[\"data\"][:]\n",
    "    dataset = torch.from_numpy(dataset).long()\n",
    "#load index to candlestick mapping from hdf5 file\n",
    "\n",
    "    index_to_candle = {}\n",
    "    for key in f.keys():\n",
    "        if key != \"data\":\n",
    "            group = f[key]\n",
    "            sizes = group['sizes'][:]\n",
    "            direction = group['direction'][()]\n",
    "            index_to_candle[int(key)] = {'sizes':tuple(sizes), 'direction':direction}\n",
    "    \n",
    "\n",
    "candle_seq_len = 65\n",
    "\n",
    "dataset = dataset.unfold(0, candle_seq_len, 1)\n",
    "input_dataset = dataset[:, :-5]\n",
    "target_dataset = dataset[: , 5:]\n",
    "\n",
    "dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 514,  883,  852,  248,  591, 1024,  615,  119,   36,  155,  664, 1024,\n",
       "          792,  536,  533,  942,   36, 1024,  406,  826,  217,  574, 1000, 1024,\n",
       "          213,  837,  213,  387,   97, 1024,  213,  152,  792,  382,   55, 1024,\n",
       "          985,  923,  942,  382,  623, 1024,  437,   14,  581,   30,  581, 1024,\n",
       "          616,  616,  962,  837,  379, 1024,  297,   97,  576,  354,  616, 1024]),\n",
       " tensor([1024,  615,  119,   36,  155,  664, 1024,  792,  536,  533,  942,   36,\n",
       "         1024,  406,  826,  217,  574, 1000, 1024,  213,  837,  213,  387,   97,\n",
       "         1024,  213,  152,  792,  382,   55, 1024,  985,  923,  942,  382,  623,\n",
       "         1024,  437,   14,  581,   30,  581, 1024,  616,  616,  962,  837,  379,\n",
       "         1024,  297,   97,  576,  354,  616, 1024,  837,  958,  222,  942,  859]),\n",
       " torch.Size([60]),\n",
       " torch.Size([60]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset[0], target_dataset[0], input_dataset[0].shape, target_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "split_idx = int(len(dataset)*0.8)\n",
    "train_data = input_dataset[:split_idx]\n",
    "train_targets = target_dataset[:split_idx]\n",
    "test_data = input_dataset[split_idx:]\n",
    "test_targets = target_dataset[split_idx:]\n",
    "\n",
    "val_split_idx = int(len(train_data)*0.8)\n",
    "val_data = train_data[val_split_idx:]\n",
    "val_targets = train_targets[val_split_idx:]\n",
    "train_data = train_data[:val_split_idx]\n",
    "train_targets = train_targets[:val_split_idx]\n",
    "\n",
    "train_dataset = TensorDataset(train_data, train_targets)\n",
    "val_dataset = TensorDataset(val_data, val_targets)\n",
    "test_dataset = TensorDataset(test_data, test_targets)\n",
    "\n",
    "batch_size = 64\n",
    "#load data into dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# function to restore candles from their codes and plot candlestick chart to writer\n",
    "import plotly.graph_objects as go\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "def full_candle_restore(candle_index:(np.array,torch.Tensor), start_price:float = 1000, number_of_candles = None, index_map = index_to_candle) -> pd.DataFrame:\n",
    "        \n",
    "        '''\n",
    "        Restore full candle from index of candle and start price\n",
    "        '''\n",
    "        tick_size = 0.25\n",
    "\n",
    "        if isinstance(candle_index, torch.Tensor):\n",
    "            candle_index = candle_index.numpy()\n",
    "        if number_of_candles is not None:\n",
    "            candle_index = candle_index[:number_of_candles]\n",
    "        \n",
    "        candle_index = candle_index[np.where(candle_index != 1024)]\n",
    "        \n",
    "        candles = []\n",
    "        for idx, cdl_idx in enumerate(candle_index):\n",
    "            \n",
    "            top_wick, body, bottom_wick = index_map[cdl_idx]['sizes']\n",
    "            direction = index_map[cdl_idx]['direction']\n",
    "            candle = {}\n",
    "            if idx == 0:\n",
    "                candle['open'] = start_price\n",
    "            \n",
    "            else:\n",
    "                candle['open'] = candles[-1]['close']\n",
    "            \n",
    "            close = candle['open'] + body * tick_size * direction\n",
    "            high = close + top_wick * tick_size if close > candle['open'] else candle['open'] + top_wick * tick_size\n",
    "            low = candle['open'] - bottom_wick * tick_size if close > candle['open'] else close - bottom_wick * tick_size\n",
    "            candle['high'] = high\n",
    "            candle['low'] = low\n",
    "            candle['close'] = close\n",
    "            candles.append(candle)\n",
    "    \n",
    "        return pd.DataFrame(candles)\n",
    "\n",
    "def write_charts_to_TB(name,writer, targets, outputs, epoch):\n",
    "    \n",
    "    \n",
    "    #convert outputs logit to candlestick codes\n",
    "    outputs = outputs.softmax(dim=1).argmax(dim=1)\n",
    "\n",
    "    \n",
    "\n",
    "    original_candles = full_candle_restore(targets)\n",
    "    predicted_candles = full_candle_restore(outputs)\n",
    "    fig1 = go.Figure(data=[go.Candlestick(x=original_candles.index,\n",
    "                open=original_candles['open'],\n",
    "                high=original_candles['high'],\n",
    "                low=original_candles['low'],\n",
    "                close=original_candles['close'])])\n",
    "    #increase chart size\n",
    "    fig1.update_layout(height=600, width=1200)\n",
    "    fig1.update_layout(xaxis_rangeslider_visible=False)\n",
    "    \n",
    "\n",
    "    fig2 = go.Figure(data=[go.Candlestick(x=predicted_candles.index,\n",
    "                    open=predicted_candles['open'],\n",
    "                    high=predicted_candles['high'],\n",
    "                    low=predicted_candles['low'],\n",
    "                    close=predicted_candles['close'])])\n",
    "    fig2.update_layout(height=600, width=1200)\n",
    "    fig2.update_layout(xaxis_rangeslider_visible=False)\n",
    "    \n",
    "    #convert figures to image and write to tensorboard\n",
    "    fig1_bytes = fig1.to_image(format=\"png\")\n",
    "    fig2_bytes = fig2.to_image(format=\"png\")\n",
    "\n",
    "    # Преобразуем байтовые данные в массив NumPy\n",
    "    fig1_image = np.array(Image.open(io.BytesIO(fig1_bytes)))\n",
    "    fig2_image = np.array(Image.open(io.BytesIO(fig2_bytes)))\n",
    "\n",
    "    # Преобразуем массивы NumPy в тензоры PyTorch\n",
    "  \n",
    "\n",
    "    # Добавляем изображения в TensorBoard\n",
    "    writer.add_image(f'{name}_original', fig1_image, epoch, dataformats='HWC')\n",
    "    writer.add_image(f'{name}_predicted', fig2_image, epoch, dataformats='HWC')\n",
    "\n",
    "def write_charts_to_sceeen(name, writer, targets, outputs, epoch):\n",
    "    \n",
    " \n",
    "    #convert outputs logit to candlestick codes\n",
    "    outputs = outputs.softmax(dim=1).argmax(dim=1)\n",
    "\n",
    "\n",
    "    original_candles = full_candle_restore(targets)\n",
    "    predicted_candles = full_candle_restore(outputs)\n",
    "    fig1 = go.Figure(data=[go.Candlestick(x=original_candles.index,\n",
    "                open=original_candles['open'],\n",
    "                high=original_candles['high'],\n",
    "                low=original_candles['low'],\n",
    "                close=original_candles['close'])])\n",
    "    #increase chart size\n",
    "    fig1.update_layout(height=600, width=1200)\n",
    "    fig1.update_layout(xaxis_rangeslider_visible=False)\n",
    "    \n",
    "\n",
    "    fig2 = go.Figure(data=[go.Candlestick(x=predicted_candles.index,\n",
    "                    open=predicted_candles['open'],\n",
    "                    high=predicted_candles['high'],\n",
    "                    low=predicted_candles['low'],\n",
    "                    close=predicted_candles['close'])])\n",
    "    fig2.update_layout(height=600, width=1200)\n",
    "    fig2.update_layout(xaxis_rangeslider_visible=False)\n",
    "    \n",
    "    fig1.show()\n",
    "    fig2.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 256):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(1)].transpose(0, 1)  # Изменение размеров для соответствия формату batch_first\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0, std=0.02)  \n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(self.embed_dim)\n",
    "        # print('Enbedding shape:', src.shape)\n",
    "        src = self.pos_encoder(src)\n",
    "        \n",
    "        output = self.transformer_encoder(src)\n",
    "        \n",
    "    \n",
    "        output = self.output_layer(output)\n",
    "        \n",
    "        return output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#check if we have CUDA or MPS and setup respecive device, if not CUDA nor MPS is available, then use CPU\n",
    "def init_model(vocab_size, embed_dim, num_heads, num_layers, dropout):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "    #device = torch.device('cpu')\n",
    "\n",
    "    print(f\"Device to be used: {device}\")\n",
    "    #Initialize model\n",
    "    torch.manual_seed(42)\n",
    "    model = TransformerModel(vocab_size, embed_dim, num_heads, num_layers, dropout)\n",
    "\n",
    "    model = model.to(device)\n",
    "    #print(model)\n",
    "    #print model device\n",
    "    next(model.parameters()).device\n",
    "    return model, device\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test model forward pass\n",
    "# for idx, (data, target) in enumerate(train_loader):\n",
    "#     model, device = init_model()\n",
    "#     data = data.to(device)\n",
    "#     target = target.to(device)\n",
    "#     output = model(data)\n",
    "#     print(f'Output shape: {output.shape}')\n",
    "#     print(f'Input data shape: {data.shape}')\n",
    "#     print(f'Target shape: {target.shape}')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define writer for tensorboard\n",
    "import os\n",
    "delete_logs = True\n",
    "if delete_logs:\n",
    "    #use python os package to delete logs including files in subfolders and subfolders itself\n",
    "    for root, dirs, files in os.walk('./runs/nq_llm_2'):\n",
    "        for file in files:\n",
    "            os.remove(os.path.join(root, file))\n",
    "        for dir in dirs:\n",
    "            for fils in os.listdir(os.path.join(root, dir)):\n",
    "                os.remove(os.path.join(root, dir, fils))\n",
    "            os.rmdir(os.path.join(root, dir))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "writer = SummaryWriter('runs/nq_llm_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device to be used: mps\n",
      "The model has 26,269,697 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "#set of model parameters\n",
    "vocab_size = dataset.max() + 1\n",
    "embed_dim = 512\n",
    "num_heads = 32\n",
    "num_layers = 8\n",
    "dropout = 0.1\n",
    "\n",
    "#initialize model, loss function and optimizer\n",
    "model, device = init_model(vocab_size, embed_dim, num_heads, num_layers, dropout)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001 )  #, weight_decay=1e-5)\n",
    "seq_len = candle_seq_len - 1\n",
    "\n",
    "loss_weights = torch.ones(seq_len).to(device)\n",
    "loss_weights[-5:] = 10.0\n",
    "\n",
    "best_vloss = float('inf')\n",
    "\n",
    "#caclulate number of trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #restore model  and optimizer state  rom checkpoint './models/nq-llm_0_2.pth'\n",
    "\n",
    "# checkpoint = torch.load('./models/nq-llm_0_2.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# best_vloss = checkpoint['vloss']\n",
    "# #print optimizer state\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     print(param_group['lr'])\n",
    "#     print(param_group['weight_decay'])\n",
    "# print(epoch)\n",
    "# print(best_vloss)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct adjust optimizer learning rate and weight decay\n",
    "\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 1e-4\n",
    "    #g['weight_decay'] = 1e-4\n",
    "\n",
    "loss_weights[-5:] = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [12477/28474], Loss: 0.712186\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vepoch_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 28\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    174\u001b[0m         group,\n\u001b[1;32m    175\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         state_steps,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    333\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 335\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adamw.py:464\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 126\u001b[0m\n\u001b[1;32m    122\u001b[0m         write_charts_to_TB(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest predicted candles sequence\u001b[39m\u001b[38;5;124m'\u001b[39m,writer, vlabels[:\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu(), voutputs[:\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39mcpu(), epoch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with Training loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Validation loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mvepoch_loss\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vepoch_loss' is not defined"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Main training loop\n",
    "try:\n",
    "    for epoch in range(start_epoch,num_epochs):\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "\n",
    "            #loss caclulation with weighted last candle\n",
    "\n",
    "            loss = loss_fn(outputs.view(-1, vocab_size), labels.view(-1))\n",
    "            loss = loss.view(-1, seq_len)\n",
    "            weighted_loss = loss * loss_weights\n",
    "            loss = weighted_loss.mean()\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():,.6f}', end='\\r', flush=True)\n",
    "      \n",
    "        \n",
    "            \n",
    "\n",
    "        #add weights and biases to tensorboard\n",
    "        weights = {}\n",
    "        biases = {}\n",
    "        grads = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                writer.add_histogram(f'weights/{name}', param, epoch)\n",
    "            elif 'bias' in name:\n",
    "                writer.add_histogram(f'biases/{name}', param, epoch)\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f'grads/{name}', param.grad, epoch)\n",
    "\n",
    "\n",
    "\n",
    "        # Test the model\n",
    "        \n",
    "        model.eval()\n",
    "        vepoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for vbatch_idx, (vdata, vlabels) in enumerate(val_loader):\n",
    "                vdata = vdata.to(device)\n",
    "                vlabels = vlabels.to(device)\n",
    "                voutputs = model(vdata)\n",
    "                #loss caclulation with weighted last candle\n",
    "                vloss = loss_fn(voutputs.view(-1, vocab_size), vlabels.view(-1))\n",
    "                vloss = vloss.view(-1, seq_len)\n",
    "                vweighted_loss = vloss * loss_weights\n",
    "                vloss = vweighted_loss.mean()\n",
    "                vepoch_loss += vloss.item()\n",
    "\n",
    "                #calculate accuracy\n",
    "                last_redicted_candle = voutputs[:,-1,:].softmax(dim=1).argmax(dim=1)\n",
    "                last_actual_candle = vlabels[:,-1]\n",
    "                correct += (last_redicted_candle == last_actual_candle).sum().item()\n",
    "                total += last_actual_candle.size(0)\n",
    "                accuracy = correct / total * 100\n",
    "                \n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{vbatch_idx + 1}/{len(val_loader)}], Validation Loss: {vloss.item():,.6f}, Validation accuracy: {accuracy:.2f}%', end='\\r', flush=True)\n",
    "    \n",
    "\n",
    "        # Save the model checkpoint if validation loss is less than best validation loss\n",
    "        if vepoch_loss/len(val_loader) < best_vloss:\n",
    "            best_vloss = vepoch_loss/len(val_loader)\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'vocab_size': vocab_size,\n",
    "                'embed_dim': embed_dim,\n",
    "                'num_heads': num_heads,\n",
    "                'num_layers': num_layers,\n",
    "                'dropout': dropout,\n",
    "                'vloss': best_vloss,\n",
    "            \n",
    "                }, './models/nq-llm_0_2.pth')\n",
    "            lr = next(iter(optimizer.param_groups))['lr']\n",
    "            weight_decay = next(iter(optimizer.param_groups))['weight_decay']\n",
    "            print(f\"Model saved at epoch {epoch+1} with validation loss {vepoch_loss/len(val_loader):.6f} Learning rate: {lr:.2e} Weight decay: {weight_decay:.2e} \")\n",
    "        #else - restore the model from previous checkpoint and reduce learning rate 5 times and increase weight decay 50%\n",
    "        # else:\n",
    "        #     checkpoint = torch.load('./models/nq-lstm.pth')\n",
    "        #     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            \n",
    "        #     for g in optimizer.param_groups:\n",
    "        #         g['lr'] = g['lr'] * 0.3\n",
    "        #         g['weight_decay'] = g['weight_decay'] * 1.1\n",
    "        #     print(f\"Model restored from epoch {epoch} with validation loss {best_vloss/len(val_loader)}\")\n",
    "        #     print(f\"Learning rate reduced to {g['lr']} and weight decay increased to {g['weight_decay']}\")\n",
    "\n",
    "        \n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {epoch_loss / len(train_loader):,.6f}, Validation Loss: {vepoch_loss / len(val_loader):,.6f}, Validation accuracy: {accuracy:.2f}% ')\n",
    "        writer.add_scalars('Loss', {'Train': epoch_loss / len(train_loader), 'Test': vepoch_loss / len(val_loader)}, epoch)\n",
    "        writer.add_scalar('Accuracy', accuracy, epoch)\n",
    "        \n",
    "        \n",
    "        # get actual lr and weight decay from optimizer and write them to tensorboard\n",
    "        lr = next(iter(optimizer.param_groups))['lr']\n",
    "        weight_decay = next(iter(optimizer.param_groups))['weight_decay']\n",
    "        writer.add_scalar('Learning rate', lr, epoch)\n",
    "        writer.add_scalar('Weight decay', weight_decay, epoch)\n",
    "        \n",
    "        #write charts to tensorboard\n",
    "        write_charts_to_TB('Test data sample',writer, vlabels[0].cpu(), voutputs[0].cpu(), epoch)\n",
    "        write_charts_to_TB('Test predicted candles sequence',writer, vlabels[:60,-1].cpu(), voutputs[:60,-1,:].cpu(), epoch)\n",
    "        \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Interrupted at epoch {epoch} with Training loss {epoch_loss:,.6f} and Validation loss {vepoch_loss:,.6f}\")\n",
    "finally:\n",
    "    writer.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function which update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_charts_to_TB('Test data sample',writer, vlabels[0].cpu(), voutputs[0].cpu(), 100, index_to_candle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interrim model parameters and optimizer state saving\n",
    "\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'batch_step': batch_idx,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'vloss': vepoch_loss,\n",
    "            }, './models/nq-llm_0_2_interrim.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which perform candle prediction in the following way:\n",
    "# 1. take last 30 tockenized candles from test dataset\n",
    "# 2. predict next tocken\n",
    "# 3. add predicted tocken to the end of tockenized candles and remove first tocken\n",
    "# 4. repeat 2-3 steps until new candle tocken (0) is predicted.\n",
    "# 5. return predicted tockenized candle along with preceding 30 tockenized candles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[53, 27, 23,  ..., 10, 20, 12],\n",
       "         [40, 26, 28,  ..., 16, 51,  5],\n",
       "         [19, 32, 21,  ...,  2, 50, 52],\n",
       "         ...,\n",
       "         [43, 34, 51,  ..., 12, 25, 29],\n",
       "         [42, 33, 50,  ..., 47, 42, 10],\n",
       "         [41, 47, 24,  ..., 46, 40, 39]], device='mps:0'),\n",
       " tensor([[1024,  847,  236,  ...,  818,  846,  671],\n",
       "         [ 847,  236,  400,  ...,  846,  671, 1024],\n",
       "         [ 236,  400,  445,  ...,  671, 1024,  598],\n",
       "         ...,\n",
       "         [ 598,  748,  364,  ...,  845,  326, 1024],\n",
       "         [ 748,  364,  986,  ...,  326, 1024,  445],\n",
       "         [ 364,  986,  711,  ..., 1024,  445,  515]], device='mps:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, (vdata, vlabels) in enumerate(test_loader):\n",
    "        vdata = vdata.to(device)\n",
    "        vlabels = vlabels.to(device)\n",
    "        voutputs = model(vdata)    \n",
    "        break \n",
    "F.softmax(voutputs,dim=1).argmax(dim=1), vlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#test the function\n",
    "write_charts_to_TB('Test data sample',writer, vlabels.cpu(), voutputs.cpu(), 200, index_to_body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
